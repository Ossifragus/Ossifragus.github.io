% @Comment Accepted or Published

@article{DataJamboree2025,
    author = {Lucy D’Agostino McGowan and Shannon Tass and Samantha Tyner and \textbf{H. Wang} and Jun Yan},
    title = {Data Jamboree: A Party of Open-Source Software Solving Real-World Data Science Problems},
    journal = {The New England Journal of Statistics in Data Science},
    year = {2025},
    pages = {1--9},
    doi = {10.51387/25-NEJSDS79},
    issn = {2693-7166},
    publisher = {New England Statistical Society}
}

@Article{ShaoWangLiangWang2025,
  author  = {Yujing Shao and Lei Wang and Heng Lian and \textbf{Wang, H.}},
  title   = {Optimal  subsampling for high-dimensional partially linear models via  machine learning methods},
  journal = {Journal of Machine Learning Research},
  year    = 2025,
  volume  = {\-},
  number  = {\-},
  pages   = {revision in review},
}

@inproceedings{NEURIPS2024_b225f5c7,
 author = {Wang, Jing and \textbf{Wang, H.} and Zhang, Hao Helen},
 booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
 pages = {98384--98418},
 publisher = {Curran Associates, Inc.},
 title = {Scale-invariant Optimal Sampling for Rare-events Data and Sparse Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/b225f5c7cd13615e9558c3931fa4e66f-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}

@article{GaoWangWang2025,
  author    = {Junzhuo Gao and Lei Wang and \textbf{Wang, H.}},
  title     = {Power enhancing probability subsampling using side information},
  journal   = {Statistics and Computing},
  year      = {2025},
  volume    = {35},
  number    = {2},
  pages     = {28},
  doi       = {10.1007/s11222-024-10556-9},
  url       = {https://doi.org/10.1007/s11222-024-10556-9},
  issn      = {1573-1375}
}

@Article{a17110524,
AUTHOR = {Liu, Jiaqi and Wang, Ziyang and \textbf{Wang, H.} and Ravishanker, Nalini},
TITLE = {Subsampling Algorithms for Irregularly Spaced Autoregressive Models},
JOURNAL = {Algorithms},
VOLUME = {17},
YEAR = {2024},
NUMBER = {11},
ARTICLE-NUMBER = {524},
URL = {https://www.mdpi.com/1999-4893/17/11/524},
ISSN = {1999-4893},
DOI = {10.3390/a17110524}
}

@article{ZhangLiWang2024,
author = {Haixiang Zhang and Yang Li and \textbf{Wang, H.}},
title = {DsubCox: A Fast Subsampling Algorithm for Cox Model with Distributed and Massive Survival Data},
journal = {International Journal of Biostatistics},
volume = {},
number = {},
pages = {Accepted},
doi = {10.1515/ijb-2024-0042},
url = {https://doi.org/10.1515/ijb-2024-0042},
year  = {2024},
}

@article{YuWangAi2024,
author = {Jun Yu and \textbf{Wang, H.} and Mingyao Ai},
title = {A Subsampling Strategy for {AIC}-based Model Averaging with Generalized Linear Models},
journal = {Technometrics},
volume = {67},
number = {1},
pages = {122--132},
year = {2025},
publisher = {ASA Website},
doi = {10.1080/00401706.2024.2407310},
URL = {https://doi.org/10.1080/00401706.2024.2407310},
eprint = {https://doi.org/10.1080/00401706.2024.2407310}
}

@Article{YangWangYan2024,
author = {Yang, Zehan and \textbf{Wang, H.} and Yan, Jun},
title = {Optimal subsampling for semi-parametric accelerated failure time models with massive survival data using a rank-based approach},
journal = {Statistics in Medicine},
volume = {43},
number = {24},
pages = {4650-4666},
keywords = {A-optimality, stochastic process, survival analysis},
doi = {https://doi.org/10.1002/sim.10200},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.10200},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.10200},
year = {2024}
}

@article{ji_lu_wang_2024,
    author = {Yuan Ji and Ying Lu and \textbf{Wang, H.}},
    title = {Editorial. Novel Statistical Methods and Designs for Clinical Trials},
    journal = {The New England Journal of Statistics in Data Science},
    volume = {2},
    number = {1},
    year = {2024},
    pages = {1--2},
    doi = {10.51387/24-NEJSDS21EDI},
    issn = {2693-7166},
    publisher = {New England Statistical Society}
}

@article{ZhangWangZhangWang2024,
author = {Yi Zhang, Lin Wang, Xiaoke Zhang and \textbf{Wang, H.}},
title = {Independence-Encouraging Subsampling for Nonparametric Additive Models},
journal = {Journal of Computational and Graphical Statistics},
volume = {33},
number = {4},
pages = {1424--1433},
year = {2024},
publisher = {ASA Website},
doi = {10.1080/10618600.2024.2326136},
URL = {https://doi.org/10.1080/10618600.2024.2326136},
eprint = {https://doi.org/10.1080/10618600.2024.2326136}
}

@article{yang2024subsampling,
  title={Subsampling approach for least squares fitting of semi-parametric accelerated failure time models to massive survival data},
  author={Yang, Zehan and \textbf{Wang, H.} and Yan, Jun},
  journal={Statistics and Computing},
  volume={34},
  number={2},
  pages={1--11},
  year={2024},
  publisher={Springer},
  url={https://rdcu.be/dyFzJ}
}

@article{wang_deng_lin_chen_xie_wu_2023,
    author = {\textbf{Wang, H.} and Xinwei Deng and Devon Lin and Ming-Hui Chen and Min-ge Xie and Jing Wu},
    title = {Editorial. Design and Analysis of Experiments for Data Science},
    journal = {The New England Journal of Statistics in Data Science},
    volume = {1},
    number = {3},
    year = {2023},
    pages = {297--298},
    doi = {10.51387/23-NEJSDS13EDI},
    issn = {2693-7166},
    publisher = {New England Statistical Society}
}

@article{dey_chen_xie_wang_wu_2023,
    author = {Dipak K. Dey and Ming-Hui Chen and Min-ge Xie and \textbf{Wang, H.} and Jing Wu},
    title = {Editorial. Modern Bayesian Methods with Applications in Data Science},
    journal = {The New England Journal of Statistics in Data Science},
    volume = {1},
    number = {2},
    year = {2023},
    pages = {123--125},
    doi = {10.51387/23-NEJSDS12EDI},
    issn = {2693-7166},
    publisher = {New England Statistical Society}
}

@Article{WangWangChen2023,
    author    = {Wang, Jing and \textbf{Wang, H.} and Chen, Kun},
    title = "{Discussion of ‘Statistical inference for streamed longitudinal data’}",
    journal = {Biometrika},
    volume = {110},
    number = {4},
    pages = {863-866},
    year = {2023},
    month = {11},
    issn = {1464-3510},
    doi = {10.1093/biomet/asad035},
    url = {https://doi.org/10.1093/biomet/asad035},
    eprint = {https://academic.oup.com/biomet/article-pdf/110/4/863/53472003/asad035.pdf},
}

@Article{ZhangZuoWangSun2023,
author    = {Zhang, Haixiang and Zuo, Lulu and \textbf{Wang, H.} and Sun, Liuquan},
title = {Approximating Partial Likelihood Estimators via Optimal Subsampling},
journal = {Journal of Computational and Graphical Statistics},
volume = {33},
number = {1},
pages = {276-288},
year = {2024},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2023.2216261},
URL = {https://doi.org/10.1080/10618600.2023.2216261}
}

@article{wu_chen_xie_wang_wu_2023,
    author = {Colin O. Wu and Ming-Hui Chen and Min-ge Xie and \textbf{Wang, H.} and Jing Wu},
    title = {Inaugural Editorial. Can We Achieve Our Mission: Fast, Accessible, Cutting-edge, and Top-quality?},
    journal = {The New England Journal of Statistics in Data Science},
    volume = {1},
    number = {1},
    year = {2023},
    pages = {1--3},
    doi = {10.51387/23-NEJSDS11EDI},
    issn = {2693-7166},
    publisher = {New England Statistical Society}
}

@Article{YuLiuWang2023,
  author  = {Jun Yu and Jiaqi Liu and \textbf{Wang, H.}},
  title   = {Information-based optimal subdata selection for non-linear models},
  journal = {Statistical Papers},
  year    = {2023},
  volume  = {64},
  number  = {4},
  pages   = {1069-1093},
  month   = {Aug},
  doi     = {10.1007/s00362-023-01430-3},
  url     = {https://link.springer.com/article/10.1007/s00362-023-01430-3}
}

@Article{WangWangNRRavishanker2023,
  author  = {Wang, Ziyang and \textbf{Wang, H.} and Ravishanker, Nalini},
title={Subsampling in Longitudinal Models},
journal={Methodology and Computing in Applied Probability},
year={2023},
month={Feb},
day={25},
volume={25},
number={1},
pages={35},
issn={1573-7713},
doi={10.1007/s11009-023-10015-4},
url={https://doi.org/10.1007/s11009-023-10015-4}
}

@Article{KimWang2023,
  author  = {Jae Kwang Kim and \textbf{Wang, H.}},
  title   = {A note on weight smoothing in survey sampling},
  journal = {Survey Methodology},
  year    = {2023},
  volume={49},
  number={1},
  pages   = {31-38}
}

@Article{YaoZouWang2022,
  author       = {Yao, Yaqiong and Zou, Jiahui and \textbf{Wang, H.}},
title = {Model constraints independent optimal subsampling probabilities for softmax regression},
journal = {Journal of Statistical Planning and Inference},
volume = {225},
pages = {188-201},
year = {2023},
issn = {0378-3758},
doi = {10.1016/j.jspi.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0378375822001112}
}

@article{WangStat2022,
author = {\textbf{Wang, H.}},
title = {A note on centering in subsample selection for linear regression},
journal = {Stat},
volume = {11},
number = {1},
pages = {e525},
keywords = {estimation efficiency, ordinary least squares, variance, weighted least squares},
doi = {10.1002/sta4.525},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.525},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.525},
abstract = {Centring is a commonly used technique in linear regression analysis. With centred data on both the responses and covariates, the ordinary least squares estimator of the slope parameter can be calculated from a model without the intercept. If a subsample is selected from a centred full data, the subsample is typically uncentred. In this case, is it still appropriate to fit a model without the intercept? The answer is yes, and we show that the least squares estimator on the slope parameter obtained from a model without the intercept is unbiased and it has a smaller variance covariance matrix in the Loewner order than that obtained from a model with the intercept. We further show that for noninformative weighted subsampling when a weighted least squares estimator is used, using the full data weighted means to relocate the subsample improves the estimation efficiency.},
year = {2022}
}

@Article{WangKim2020,
  author  = {\textbf{Wang, H.} and Jae Kwang Kim},
  title   = {Maximum sampled conditional likelihood for informative subsampling},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {332},
  pages   = {1--50},
  url     = {http://jmlr.org/papers/v23/21-0506.html}
}

@Article{YangWangYan2022,
author = {Yang, Zehan and \textbf{Wang, H.} and Yan, Jun},
title = {Optimal subsampling for parametric accelerated failure time models with massive survival data},
journal = {Statistics in Medicine},
volume = {41},
number = {27},
pages = {5421-5431},
keywords = {A-optimality, censoring, L-optimality, survival analysis},
doi = {10.1002/sim.9576},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9576},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9576},
abstract = {With increasing availability of massive survival data, researchers need valid statistical inferences for survival modeling whose computation is not limited by computer memories. Existing works focus on relative risk models using the online updating and divide-and-conquer strategies. The subsampling strategy has not been available due to challenges in developing the asymptotic properties of the estimator under semiparametric models with censored data. This article tackles optimal subsampling algorithms to fast approximate the maximum likelihood estimator for parametric accelerate failure time models with massive survival data. We derive the asymptotic distributions of the subsampling estimator and the optimal sampling probabilities that minimize the asymptotic mean squared error of the estimator. A feasible two-step algorithm is proposed where the optimal sampling probabilities in the second step are estimated based on a pilot sample in the first step. The asymptotic properties of the two-step estimator are established. The performance of the estimator is validated in a simulation study. A real data analysis illustrates the usefulness of the methods.},
year = {2022}
}


@Article{ZhuWangZhangLiang2022,
author = {Rong Zhu and {\textbf{Wang, H.}} and Xinyu Zhang and Hua Liang},
title = {A Scalable Frequentist Model Averaging Method},
journal = {Journal of Business \& Economic Statistics},
volume = {41},
number = {4},
pages = {1228-1237},
year = {2023},
publisher = {Taylor & Francis},
doi = {10.1080/07350015.2022.2116442},
URL = {https://doi.org/10.1080/07350015.2022.2116442},
eprint = {https://doi.org/10.1080/07350015.2022.2116442}
}

@Article{WangWangXiong2020,
  author       = {Wang, Jing and \textbf{Wang, H.} and Xiong, Shifeng},
title = {Unweighted estimation based on optimal sample under measurement constraints},
journal = {Canadian Journal of Statistics},
volume = {52},
number = {1},
pages = {291-309},
keywords = {Generalized linear models, massive data, martingale central limit theorem},
doi = {https://doi.org/10.1002/cjs.11753},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11753},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11753},
year = {2024}
}


@Article{LeeSchifanoWang2021mix,
    author = {Lee, Joochul and Schifano, Elizabeth and \textbf{Wang, H.} },
     TITLE = {Sampling-based Gaussian Mixture Regression for Big Data},
   JOURNAL = {J. Data Sci.},
  FJOURNAL = {Journal of Data Science},
      YEAR = {2023},
    VOLUME = {21},
    NUMBER = {1},
     PAGES = {158-172},
      ISSN = {1680-743X},
       DOI = {10.6339/22-JDS1057},
      SICI = {1680-743X(2023)21:1<158:SBGMRF>2.0.CO;2-8},
}

@article{EEENG6839,
  title={Tap Water Lead Monitoring through Citizen Science: The Influence of Socioeconomics and Participation on Environmental Literacy, Behavior, and Communication.},
  author={Sarah Jakositz and Roozbeh Ghasemi and Bridie McGreavy and {\textbf{Wang, H.}} and Scott Greenwood and Weiwei Mo},
  journal={Journal of Environmental Engineering},
  volume=148,
  number=10,
  pages=04022060,
  year=2022,
  publisher={American Society of Civil Engineers},
	doi = {10.1061/(ASCE)EE.1943-7870.0002055},
URL = {https://ascelibrary.org/doi/abs/10.1061/%28ASCE%29EE.1943-7870.0002055},
eprint = {https://ascelibrary.org/doi/pdf/10.1061/%28ASCE%29EE.1943-7870.0002055}
}

@Article{WangWangYan2022,
  author       = {Wang, Feng and \textbf{Wang, H.} and Yan, Jun},
title = {Diagnostic Tests for the Necessity of Weight in Regression With Survey Data},
journal = {International Statistical Review},
volume = 91,
number = 1,
pages = {55-71},
doi = {10.1111/insr.12509},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12509},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12509},
year = 2023
}

@Article{WangZouWang2022,
author={Wang, Jing and Zou, Jiahui and \textbf{Wang, H.}},
journal={IEEE Transactions on Information Theory},
title={Sampling With Replacement vs Poisson Sampling: A Comparative Study in Optimal Subsampling},
year={2022},
volume={68},
number={10},
pages={6605-6630},
doi={10.1109/TIT.2022.3176955}}

@Article{YuWang2021,
  author       = {Yu, Jun and \textbf{Wang, H.}},
	title={Subdata selection algorithm for linear model discrimination},
	journal={Statistical Papers},
	year=2022,
  volume={63},
  number={6},
  pages={1883--1906},
  publisher={Springer},
	doi={10.1007/s00362-022-01299-8},
	url={https://doi.org/10.1007/s00362-022-01299-8}
}

@Article{YaoZouWang2021,
  title={Optimal poisson subsampling for softmax regression},
  author={Yao, Yaqiong and Zou, Jiahui and \textbf{Wang, H.}},
  journal={Journal of Systems Science and Complexity},
  volume={36},
  number={4},
  pages={1609--1625},
  year={2023},
  publisher={Springer}
}

@InProceedings{WangZhangWang2021,
  title = 	 {Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data},
	author			 = {\textbf{Wang, H.} and Zhang, Aonan and Wang, Chong},
  booktitle = 	 {Proceedings of The 35 Conference on Neural Information Processing Systems ({NeurIPS}).},
  year = 	 2021,
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@InProceedings{pmlr-v130-wang21a,
  title = 	 {A comparative study on sampling with replacement vs Poisson sampling in optimal subsampling },
  author =       {\textbf{Wang, H.} and Zou, Jiahui},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {289--297},
  year = 	 2021,
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 130,
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/wang21a/wang21a.pdf},
  url = 	 {http://proceedings.mlr.press/v130/wang21a.html},
}

@Article{WangZhangLiangRuppert2021,
author    = {\textbf{Wang, H.} and Zhang, Dixin and Liang, Hua and Ruppert, David},
title = {Iterative Likelihood: A Unified Inference Tool},
journal = {Journal of Computational and Graphical Statistics},
volume = {30},
number = {4},
pages = {920-933},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2021.1904961},
URL = {https://doi.org/10.1080/10618600.2021.1904961},
eprint = {https://doi.org/10.1080/10618600.2021.1904961}
}


@Article{LeeSchifanoWang2021,
  author = {Lee, Joochul and Schifano, Elizabeth and \textbf{Wang, H.} },
title = {Fast Optimal Subsampling Probability Approximation for Generalized Linear Models},
journal = {Econometrics and Statistics},
volume = 29,
pages = {224-237},
year = 2024,
issn = {2452-3062},
doi = {https://doi.org/10.1016/j.ecosta.2021.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S2452306221000290},
keywords = {Generalized linear models, Massive data, Optimal subsampling, Randomized algorithm},
abstract = {For massive data, subsampling techniques are popular to mitigate computational burden by reducing the data size. In a subsampling approach, subsampling probabilities for each data point are specified to obtain an informative sub-data, and then estimates based on the sub-data are obtained to approximate estimates from the full data. Assigning subsampling probabilities based on minimization of the asymptotic mean squared error of the estimator from a general subsample (A-optimality criterion) is a popular approach, however, it is still computationally demanding to calculate the probabilities under this setting. To efficiently approximate the A-optimal subsampling probabilities for generalized linear models, randomized algorithms are proposed. To develop the algorithms, the Johnson-Lindenstrauss Transform and Subsampled Randomized Hadamard Transform are used. Additionally, optimal subsampling probabilities are derived for the Gaussian linear model in the case where both the regression coefficients and dispersion parameter are of interest, and algorithms are developed to approximate the optimal subsampling probabilities. Simulation studies indicate that the estimators based on the developed algorithms have excellent performance for statistical inference and have substantial savings in computing time compared to the direct calculation of the A-optimal subsampling probabilities.}
}

@Article{ZuoZhangWangSun2020,
author={Zuo, Lulu and Zhang, Haixiang and \textbf{Wang, H.} and Sun, Liuquan},
title={Optimal subsample selection for massive logistic regression with distributed data},
journal={Computational Statistics},
year={2021},
volume={36},
number={4},
pages={2535-2562},
doi={10.1007/s00180-021-01089-0},
url={https://doi.org/10.1007/s00180-021-01089-0}
}

@Article{HaimWang2021,
  author       = {Bar, Haim and \textbf{Wang, H.}},
  title        = {Reproducible Science with {LaTeX}.},
  journal      = {Journal of Data Science.},
  volume={19},
  number={1},
  year 	       = {2021},
  pages     = {111–125}
}


@Article{YaoWang2021JDS,
  author       = {Yao, Yaqiong and \textbf{Wang, H.}},
  title        = {A Review on Optimal Subsampling Methods for Massive Datasets},
  journal      = {Journal of Data Science},
  volume={19},
  number={1},
  year 	       = {2021},
  pages     = {151–172}
}

@article{zuo2021sampling,
  title={Sampling-based estimation for massive survival data with additive hazards model},
  author={Zuo, Lulu and Zhang, Haixiang and \textbf{Wang, H.} and Liu, Lei},
  journal={Statistics in medicine},
  volume={40},
  number={2},
  pages={441--450},
  year={2021},
  publisher={Wiley Online Library}
}

@article{ZHANG2021107072,
title = {Distributed subdata selection for big data via sampling-based approach},
journal = {Computational Statistics \& Data Analysis},
volume = {153},
pages = {107072},
year = {2021},
issn = {0167-9473},
doi = {10.1016/j.csda.2020.107072},
url = {https://www.sciencedirect.com/science/article/pii/S0167947320301638},
author = {Haixiang Zhang and \textbf{Wang, H.}},
keywords = {Allocation sizes, Big data, Distributed subsampling, Optimal subsampling, Regression diagnostic},
abstract = {With the development of modern technologies, it is possible to gather an extraordinarily large number of observations. Due to the storage or transmission burden, big data are usually scattered at multiple locations. It is difficult to transfer all of data to the central server for analysis. A distributed subdata selection method for big data linear regression model is proposed. Particularly, a two-step subsampling strategy with optimal subsampling probabilities and optimal allocation sizes is developed. The subsample-based estimator effectively approximates the ordinary least squares estimator from the full data. The convergence rate and asymptotic normality of the proposed estimator are established. Simulation studies and an illustrative example about airline data are provided to assess the performance of the proposed method.}
}

@Article{PronzatoWang2020,
  author       = {Pronzato, Luc and \textbf{Wang, H.}},
  title        = {Sequential online subsampling for thinning experimental designs.},
  journal      = {Journal of Statistical Planning and Inference},
volume = "212",
pages = "169 - 193",
year = "2021",
issn = "0378-3758",
doi = "10.1016/j.jspi.2020.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S0378375820300999",
}

@Inproceedings{YaoWang2021,
author="Yao, Yaqiong and \textbf{Wang, H.}",
editor="Zhao, Yichuan and Chen, (Din) Ding-Geng",
title="A Selective Review on Statistical Techniques for Big Data",
bookTitle="Modern Statistical Methods for Health Research",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="223--245",
doi="10.1007/978-3-030-72437-5_11",
url="https://doi.org/10.1007/978-3-030-72437-5_11"
 }

@InProceedings{Wang2020RareICML,
  title = 	 {Logistic Regression for Massive Data with Rare Events},
  author =       {\textbf{Wang, H.}},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning ({ICML})},
  pages = 	 {9829--9836},
  year = 	 {2020},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/wang20a/wang20a.pdf},
  url = 	 {http://proceedings.mlr.press/v119/wang20a.html},
}

@article{yu2020quasi,
author = {Jun Yu and \textbf{Wang, H.} and Mingyao Ai and Huiming Zhang},
title = {Optimal Distributed Subsampling for Maximum Quasi-Likelihood Estimators With Massive Data},
journal = {Journal of the American Statistical Association},
volume = {117},
number = {537},
pages = {265-276},
year  = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2020.1773832},
URL = {https://doi.org/10.1080/01621459.2020.1773832},
eprint = {https://doi.org/10.1080/01621459.2020.1773832}
}


@article{ChengWangYang2020,
  title={Information-Based Optimal Subdata Selection for Big Data Logistic Regression},
  author={Cheng, Qianshun and \textbf{Wang, H.} and Yang, Min},
  journal={Journal of Statistical Planning and Inference},
volume = "209",
pages = "112 - 122",
  doi={10.1016/j.jspi.2020.03.004},
  year={2020}
}

@article{lee2020online,
  title={Online updating method to correct for measurement error in big data streams},
  author={Lee, JooChul and \textbf{Wang, H.} and Schifano, Elizabeth D},
  journal={Computational Statistics \& Data Analysis},
  volume={149},
  pages={106976},
  year={2020},
  publisher={Elsevier}
}

@article{hu2021most,
  title={Most Likely Optimal Subsampled Markov Chain Monte Carlo},
  author={Hu, Guanyu and \textbf{Wang, H.}},
  journal={Journal of Systems Science and Complexity},
  volume={34},
  number={3},
  pages={1121--1134},
  year={2021},
  publisher={Springer}
}

@article{zhou2020induction,
author = {Zhou, Yuxin and Qiu, Liyan and \textbf{Wang, H.} and Chen, Xuanmao},
title = {Induction of activity synchronization among primed hippocampal neurons out of random dynamics is key for trace memory formation and retrieval},
journal = {The FASEB Journal},
volume = {34},
number = {3},
pages = {3658-3676},
doi = {10.1096/fj.201902274R},
year = {2020}
}

@article{wang2020optimal,
    author = {\textbf{Wang, H.} and Ma, Yanyuan},
    title = "{Optimal subsampling for quantile regression in big data}",
    journal = {Biometrika},
    volume = 108,
    number = 1,
    pages = {99-112},
    year = 2021,
    month = 07,
    abstract = "{We investigate optimal subsampling for quantile regression. We derive the asymptotic distribution of a general subsampling estimator and then derive two versions of optimal subsampling probabilities. One version minimizes the trace of the asymptotic variance-covariance matrix for a linearly transformed parameter estimator and the other minimizes that of the original parameter estimator. The former does not depend on the densities of the responses given covariates and is easy to implement. Algorithms based on optimal subsampling probabilities are proposed and asymptotic distributions, and the asymptotic optimality of the resulting estimators are established. Furthermore, we propose an iterative subsampling procedure based on the optimal subsampling probabilities in the linearly transformed parameter estimation which has great scalability to utilize available computational resources. In addition, this procedure yields standard errors for parameter estimators without estimating the densities of the responses given the covariates. We provide numerical examples based on both simulated and real data to illustrate the proposed method.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asaa043},
    url = {https://doi.org/10.1093/biomet/asaa043},
    eprint = {https://academic.oup.com/biomet/article-pdf/108/1/99/36441025/asaa043.pdf},
}

@article{wang2019more,
  title={More Efficient Estimation for Logistic Regression with Optimal Subsamples},
  author={\textbf{Wang, H.}},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={132},
  pages={1--59},
  year={2019}
}

@article{xue2020online,
author = {Xue, Yishu and \textbf{Wang, H.} and Yan, Jun and Schifano, Elizabeth D.},
title = {An online updating approach for testing the proportional hazards assumption with streams of survival data},
journal = {Biometrics},
volume = {76},
number = {1},
pages = {171-182},
keywords = {Cox model, diagnostics, Schoenfeld residuals},
doi = {10.1111/biom.13137},
year = {2020}
}

@article{wang2019divide,
  title={Divide-and-conquer information-based optimal subdata selection algorithm},
  author={\textbf{Wang, H.}},
  journal={Journal of Statistical Theory and Practice},
  volume={13},
  number={3},
  pages={46},
  year={2019},
  publisher={Springer},
  doi={10.1007/s42519-019-0048-5}
}

@article{ai2018optimal,
  title={Optimal subsampling algorithms for big data regressions},
  author={Ai, Mingyao and Yu, Jun and Zhang, Huiming and \textbf{Wang, H.}},
  journal={Statistica Sinica},
  volume={31},
  number={2},
  year=2021,
  pages={749-772},
  doi={10.5705/ss.202018.0439}
}

@article{zhou2019comparative,
  title={Comparative Phosphoproteomic Profiling of Type {III} Adenylyl Cyclase Knockout and Control, Male, and Female Mice},
  author={Zhou, Yuxin and Qiu, Liyan and Sterpka, Ashley and \textbf{Wang, H.} and Chu, Feixia and Chen, Xuanmao},
  journal={Frontiers in cellular neuroscience},
  volume=13,
  pages=34,
  year=2019,
  publisher={Frontiers}
}

@article{yao2019optimal,
  title={Optimal subsampling for softmax regression},
  author={Yao, Yaqiong and \textbf{Wang, H.}},
  journal={Statistical Papers},
  volume=60,
  number=2,
  pages={235--249},
  year=2019,
  publisher={Springer}
}

@article{WangYangStufken2019,
  title={Information-based optimal subdata selection for big data linear regression},
  author={\textbf{Wang, H.} and Yang, Min and Stufken, John},
  journal={Journal of the American Statistical Association},
  volume=114,
  number=525,
  pages={393--405},
  year=2019,
  publisher={Taylor \& Francis}
}

@article{WangZhuMa2018,
  title={Optimal subsampling for large sample logistic regression},
  author={\textbf{Wang, H.} and Zhu, Rong and Ma, Ping},
  journal={Journal of the American Statistical Association},
  volume=113,
  number=522,
  pages={829--844},
  year=2018,
  publisher={Taylor \& Francis}
}

@article{stang2018influences,
  title={Influences of water quality and climate on the water-energy nexus: A spatial comparison of two water systems},
  author={Stang, Shannon and \textbf{Wang, H.} and Gardner, Kevin H and Mo, Weiwei},
  journal={Journal of environmental management},
  volume={218},
  pages={613--621},
  year={2018},
  publisher={Elsevier}
}

@article{zhang2017linear,
  title={Linear model selection when covariates contain errors},
  author={Zhang, Xinyu and \textbf{Wang, H.} and Ma, Yanyuan and Carroll, Raymond J},
  journal={Journal of the American Statistical Association},
  volume={112},
  number={520},
  pages={1553--1561},
  year={2017},
  publisher={Taylor \& Francis}
}

@incollection{li2016joint,
  title={Joint analysis of longitudinal data and informative observation times with time-dependent random effects},
  author={Li, Yang and He, Xin and \textbf{Wang, H.} and Sun, Jianguo},
  booktitle={New Developments in Statistical Modeling, Inference and Application},
  pages={37--51},
  year={2016},
  publisher={Springer}
}

@incollection{lane2016conditional,
  title={Conditional Inference in Two-Stage Adaptive Experiments via the Bootstrap},
  author={Lane, Adam and \textbf{Wang, H.} and Flournoy, Nancy},
  booktitle={{mODa} 11-Advances in Model-Oriented Design and Analysis},
  pages={173--181},
  year={2016},
  publisher={Springer}
}

@article{mo2016understanding,
  title={Understanding the influence of climate change on the embodied energy of water supply},
  author={Mo, Weiwei and \textbf{Wang, H.} and Jacobs, Jennifer M},
  journal={Water research},
  volume={95},
  pages={220--229},
  year={2016},
  publisher={Elsevier}
}

@article{li2016regression,
  title={Regression analysis of longitudinal data with correlated censoring and observation times},
  author={Li, Yang and He, Xin and \textbf{Wang, H.} and Sun, Jianguo},
  journal={Lifetime data analysis},
  volume={22},
  number={3},
  pages={343--362},
  year={2016},
  publisher={Springer}
}

@article{wang2016focused,
  title={The focused information criterion for varying-coefficient partially linear measurement error models},
  author={\textbf{Wang, H.} and Chen, Xinjie and Flournoy, Nancy},
  journal={Statistical Papers},
  volume={57},
  number={1},
  pages={99--113},
  year={2016},
  publisher={Springer}
}


@article{li2015semiparametric,
  title={Semiparametric regression of multivariate panel count data with informative observation times},
  author={Li, Yang and He, Xin and \textbf{Wang, H.} and Zhang, Bin and Sun, Jianguo},
  journal={Journal of Multivariate Analysis},
  volume=140,
  pages={209--219},
  year=2015,
  publisher={Elsevier}
}

@article{WangSchaebenKeidel2015,
  title={Optimized Subsampling for Logistic Regression with Imbalanced Large Datasets},
  author={\textbf{Wang, H.} and Schaeben, H. and Keidel, F.},
  journal={Proceeding of the 17th annual conference of the International Association for Mathematical Geosciences},
  volume={ },
  pages={1113-1119},
  year={2015}
}

@article{wang2015consistency,
  title={On the consistency of the maximum likelihood estimator for the three parameter lognormal distribution},
  author={\textbf{Wang, H.} and Flournoy, Nancy},
  journal={Statistics \& Probability Letters},
  volume={105},
  pages={57--64},
  year={2015},
  publisher={Elsevier}
}

@article{wang2015focused,
  title={Focused and model average estimation for regression analysis of panel count data},
  author={\textbf{Wang, H.} and Li, Yang and Sun, Jianguo},
  journal={Scandinavian Journal of Statistics},
  volume={42},
  number={3},
  pages={732--745},
  year={2015},
  publisher={Wiley Online Library}
}

@article{wang2014new,
  title={A new bounded log-linear regression model},
  author={\textbf{Wang, H.} and Flournoy, Nancy and Kpamegan, Eloi},
  journal={Metrika},
  volume={77},
  number={5},
  pages={695--720},
  year={2014},
  publisher={Springer}
}

@incollection{wang2013optimal,
  title={Optimal design for the bounded log-linear regression model},
  author={\textbf{Wang, H.} and Pepelyshev, Andrey and Flournoy, Nancy},
  booktitle={{mODa} 10--Advances in Model-Oriented Design and Analysis},
  pages={237--245},
  year={2013},
  publisher={Springer}
}

@article{wang2013interval,
  title={Interval estimation by frequentist model averaging},
  author={\textbf{Wang, H.} and Zhou, Sherry ZF},
  journal={Communications in Statistics-Theory and Methods},
  volume={42},
  number={23},
  pages={4342--4356},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{wang2013adaptive,
  title={Adaptive LASSO for varying-coefficient partially linear measurement error models},
  author={\textbf{Wang, H.} and Zou, Guohua and Wan, Alan TK},
  journal={Journal of Statistical Planning and Inference},
  volume={143},
  number={1},
  pages={40--54},
  year={2013},
  publisher={Elsevier}
}

@article{wang2012model,
  title={Model averaging for varying-coefficient partially linear measurement error models},
  author={\textbf{Wang, H.} and Zou, Guohua and Wan, Alan TK and others},
  journal={Electronic Journal of Statistics},
  volume={6},
  pages={1017--1039},
  year={2012},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{wang2012objective,
  title={Objective Bayesian analysis for a truncated model},
  author={\textbf{Wang, H.} and Sun, Dongchu},
  journal={Statistics \& Probability Letters},
  volume={82},
  number={12},
  pages={2125--2135},
  year={2012},
  publisher={Elsevier}
}

@article{WangZou2012,
  title	       = {Frequentist model averaging estimation for linear
                  errors-in-variables models (in Chinese)},
  author       = {\textbf{Wang, H.} and Zou, G.},
  journal      = {Journal of Systems Science and Mathematical Science},
  volume       = {32},
  number       = {2},
  pages	       = {1-14},
  year	       = {2012}
}

@article{kozak2010stochastic,
  title={On stochastic optimization in sample allocation among strata},
  author={Kozak, Marcin and \textbf{Wang, H.}},
  journal={Metron},
  volume={68},
  number={1},
  pages={95--103},
  year={2010},
  publisher={Springer}
}

@article{wang2009frequentist,
  title={Frequentist model averaging estimation: a review},
  author={\textbf{Wang, H.} and Zhang, Xinyu and Zou, Guohua},
  journal={Journal of Systems Science and Complexity},
  volume={22},
  number={4},
  pages={732-748},
  year={2009},
  publisher={Springer}
}

@article{FengWang2008,
  title	       = {Sampling procedures for inspection by
                  attributes-Part 3: Skip-lot sampling procedures (in
                  Chinese)},
  author       = {Feng, S. and Ding, W. and \textbf{Wang, H.} and Yu, Z. and Chen,
                  Y. and Zhang, Y. and Xiao, H.},
  journal      = {Chinese National Standard, GB/T2828.3-2008.},
  year	       = 2008
}


 %%% Local Variables:
%%% mode:latex
%%% TeX-engine: xetex
%%% TeX-command-extra-options: "-shell-escape"
%%% TeX-master: "CV.tex"
%%% End: